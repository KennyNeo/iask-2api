é¡¹ç›® 'iask-2api' çš„ç»“æ„æ ‘:
ğŸ“‚ iask-2api/
    ğŸ“„ .env
    ğŸ“„ .env.example
    ğŸ“„ .gitignore
    ğŸ“„ AsyncGenerator[bytes
    ğŸ“„ Dockerfile
    ğŸ“„ JSONResponse
    ğŸ“„ StreamingResponse
    ğŸ“„ Tuple[str
    ğŸ“„ docker-compose.yml
    ğŸ“„ main.py
    ğŸ“„ nginx.conf
    ğŸ“„ requirements.txt
    ğŸ“„ str
    ğŸ“‚ app/
        ğŸ“‚ core/
            ğŸ“„ __init__.py
            ğŸ“„ config.py
        ğŸ“‚ providers/
            ğŸ“„ __init__.py
            ğŸ“„ base_provider.py
            ğŸ“„ iask_provider.py
        ğŸ“‚ utils/
            ğŸ“„ sse_utils.py
================================================================================

--- æ–‡ä»¶è·¯å¾„: .env ---

# --- æ–‡ä»¶è·¯å¾„: .env ---

# [è‡ªåŠ¨å¡«å……] iask-2api ç”Ÿäº§ç¯å¢ƒé…ç½® (v1.0 - åŒ¿åç‰ˆ)
# è¯¥æ–‡ä»¶ç”± Genesis Protocol Â· Î© (Omega) ç‰ˆè‡ªåŠ¨ç”Ÿæˆã€‚

# --- å®‰å…¨é…ç½® ---
# ç”¨äºä¿æŠ¤æ‚¨çš„ API æœåŠ¡çš„è®¿é—®å¯†é’¥ï¼Œè¯·ä¿®æ”¹ä¸ºæ‚¨è‡ªå·±çš„å¤æ‚å¯†é’¥ã€‚
API_MASTER_KEY=1

# --- ç«¯å£é…ç½® ---
# Nginx å¯¹å¤–æš´éœ²çš„ç«¯å£
NGINX_PORT=8088



--- æ–‡ä»¶è·¯å¾„: .env.example ---

# --- æ–‡ä»¶è·¯å¾„: .env.example ---

# ====================================================================
# iask-2api é…ç½®æ–‡ä»¶æ¨¡æ¿ (v1.0 - åŒ¿åç‰ˆ)
# ====================================================================
#
# è¯·å°†æ­¤æ–‡ä»¶é‡å‘½åä¸º ".env" å¹¶å¡«å…¥æ‚¨çš„å¯†é’¥ã€‚
# æœ¬é¡¹ç›®ä¸ºåŒ¿åæ¨¡å¼ï¼Œæ— éœ€ä»»ä½• Cookie æˆ–å…¶ä»–å‡­è¯ï¼
#

# --- æ ¸å¿ƒå®‰å…¨é…ç½® (å¿…é¡»è®¾ç½®) ---
# ç”¨äºä¿æŠ¤æ‚¨ API æœåŠ¡çš„è®¿é—®å¯†é’¥ã€‚
API_MASTER_KEY=sk-iask-2api-default-key-please-change-me

# --- éƒ¨ç½²é…ç½® (å¯é€‰) ---
# Nginx å¯¹å¤–æš´éœ²çš„ç«¯å£
NGINX_PORT=8088



--- æ–‡ä»¶è·¯å¾„: .gitignore ---

.env

--- æ–‡ä»¶è·¯å¾„: AsyncGenerator[bytes ---



--- æ–‡ä»¶è·¯å¾„: Dockerfile ---

# Dockerfile
# ä½¿ç”¨å®˜æ–¹çš„ Python slim é•œåƒä½œä¸ºåŸºç¡€
FROM python:3.11-slim-bookworm

# è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œä¼˜åŒ– Python è¿è¡Œ
ENV PYTHONDONTWRITEBYTECODE=1
ENV PYTHONUNBUFFERED=1

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# æ­¥éª¤ 1: å®‰è£…ç³»ç»Ÿä¾èµ–ï¼ŒåŒ…æ‹¬ Playwright éœ€è¦çš„åº“
RUN apt-get update && apt-get install -y \
    wget \
    gnupg \
    software-properties-common \
    && rm -rf /var/lib/apt/lists/*

# æ­¥éª¤ 2: å®‰è£… Python ä¾èµ–
COPY requirements.txt .
RUN pip install --no-cache-dir --upgrade pip && \
    pip install --no-cache-dir -r requirements.txt

# æ­¥éª¤ 3: åˆ›å»ºä¸€ä¸ªé root ç”¨æˆ·æ¥è¿è¡Œåº”ç”¨
RUN useradd --create-home appuser

# æ­¥éª¤ 4: ä¸º appuser å®‰è£… Playwright æµè§ˆå™¨
# è®¾ç½®æµè§ˆå™¨å®‰è£…è·¯å¾„ä¸º appuser çš„ home ç›®å½•ï¼Œè¿™æ · appuser å°±èƒ½æ‰¾åˆ°å®ƒ
ENV PLAYWRIGHT_BROWSERS_PATH=/home/appuser/.cache/ms-playwright
# ä»¥ root èº«ä»½æ‰§è¡Œå®‰è£…ï¼Œä½†æ–‡ä»¶ä¼šå†™å…¥åˆ°ä¸Šé¢æŒ‡å®šçš„ appuser ç›®å½•
RUN playwright install chromium
# å®‰è£…æµè§ˆå™¨è¿è¡Œæ‰€éœ€çš„ç³»ç»Ÿçº§ä¾èµ–ï¼ˆè¿™éœ€è¦ root æƒé™ï¼‰
RUN playwright install-deps chromium

# æ­¥éª¤ 5: å¤åˆ¶æ‰€æœ‰åº”ç”¨ä»£ç ï¼Œå¹¶å°†æ‰€æœ‰æƒäº¤ç»™ appuser
COPY . .
RUN chown -R appuser:appuser /app

# æ­¥éª¤ 6: åˆ‡æ¢åˆ° appuser ç”¨æˆ·
USER appuser

# æš´éœ² FastAPI åº”ç”¨è¿è¡Œçš„ç«¯å£
EXPOSE 8000

# å¯åŠ¨åº”ç”¨çš„å‘½ä»¤
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]


--- æ–‡ä»¶è·¯å¾„: JSONResponse ---



--- æ–‡ä»¶è·¯å¾„: StreamingResponse ---



--- æ–‡ä»¶è·¯å¾„: Tuple[str ---



--- æ–‡ä»¶è·¯å¾„: docker-compose.yml ---

services:
  nginx:
    image: nginx:latest
    container_name: iask-2api-nginx
    restart: always
    ports:
      - "${NGINX_PORT:-8088}:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - app
    networks:
      - iask-net

  app:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: iask-2api-app
    restart: unless-stopped
    env_file:
      - .env
    networks:
      - iask-net

networks:
  iask-net:
    driver: bridge



--- æ–‡ä»¶è·¯å¾„: main.py ---

# main.py
import logging
from contextlib import asynccontextmanager
from typing import Optional

from fastapi import FastAPI, Request, HTTPException, Depends, Header
from fastapi.responses import JSONResponse
import uvicorn

from app.core.config import settings
from app.providers.iask_provider import IaskProvider

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

@asynccontextmanager
async def lifespan(app: FastAPI):
    logger.info(f"åº”ç”¨å¯åŠ¨ä¸­... {settings.APP_NAME} v{settings.APP_VERSION}")
    logger.info(f"æœåŠ¡å°†åœ¨ http://localhost:{settings.NGINX_PORT} ä¸Šå¯ç”¨")
    yield
    logger.info("åº”ç”¨å·²å…³é—­ã€‚")

app = FastAPI(
    title=settings.APP_NAME,
    version=settings.APP_VERSION,
    description=settings.DESCRIPTION,
    lifespan=lifespan
)

provider = IaskProvider()

async def verify_api_key(authorization: Optional[str] = Header(None)):
    if settings.API_MASTER_KEY and settings.API_MASTER_KEY != "1":
        if not authorization or "bearer" not in authorization.lower():
            raise HTTPException(status_code=401, detail="éœ€è¦ Bearer Token è®¤è¯ã€‚")
        token = authorization.split(" ")[-1]
        if token != settings.API_MASTER_KEY:
            raise HTTPException(status_code=403, detail="æ— æ•ˆçš„ API Keyã€‚")

@app.post("/v1/chat/completions", dependencies=[Depends(verify_api_key)])
async def chat_completions(request: Request):
    try:
        request_data = await request.json()
        return await provider.chat_completion(request_data)
    except Exception as e:
        logger.error(f"å¤„ç†èŠå¤©è¯·æ±‚æ—¶å‘ç”Ÿé¡¶å±‚é”™è¯¯: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"å†…éƒ¨æœåŠ¡å™¨é”™è¯¯: {str(e)}")

@app.get("/v1/models", dependencies=[Depends(verify_api_key)], response_class=JSONResponse)
async def list_models():
    return await provider.get_models()

@app.get("/", summary="æ ¹è·¯å¾„", response_class=JSONResponse)
def root():
    return {"message": f"æ¬¢è¿æ¥åˆ° {settings.APP_NAME} v{settings.APP_VERSION}. æœåŠ¡è¿è¡Œæ­£å¸¸ã€‚"}

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)


--- æ–‡ä»¶è·¯å¾„: nginx.conf ---

# --- æ–‡ä»¶è·¯å¾„: nginx.conf ---

worker_processes auto;

events {
    worker_connections 1024;
}

http {
    upstream iask_backend {
        # ä½¿ç”¨ ip_hash ç¡®ä¿æ¥è‡ªåŒä¸€å®¢æˆ·ç«¯çš„è¯·æ±‚è¢«è½¬å‘åˆ°åŒä¸€ä¸ª workerï¼Œ
        # è¿™å¯¹äºéœ€è¦ä¼šè¯ä¿æŒçš„åœºæ™¯ï¼ˆå¦‚ Cloudscraper å’ŒåŠ¨æ€ä¼šè¯ï¼‰è‡³å…³é‡è¦ã€‚
        ip_hash;
        server app:8000;
    }

    server {
        listen 80;
        server_name localhost;

        location / {
            proxy_pass http://iask_backend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            
            # --- æµå¼ä¼ è¾“å…³é”®ä¿®å¤ (Streaming Critical Fix) ---
            proxy_buffering off;
            proxy_cache off;
            proxy_set_header Connection '';
            proxy_http_version 1.1;
            chunked_transfer_encoding off;
            proxy_set_header X-Accel-Buffering no;
            proxy_read_timeout 1d; # å»¶é•¿è¶…æ—¶ä»¥æ”¯æŒé•¿è½®è¯¢
        }
    }
}


--- æ–‡ä»¶è·¯å¾„: requirements.txt ---

# requirements.txt
fastapi
uvicorn[standard]
httpx
pydantic-settings
python-dotenv
requests
beautifulsoup4
html2text
playwright


--- æ–‡ä»¶è·¯å¾„: str ---



--- æ–‡ä»¶è·¯å¾„: app\core\__init__.py ---



--- æ–‡ä»¶è·¯å¾„: app\core\config.py ---

# app/core/config.py
from pydantic_settings import BaseSettings, SettingsConfigDict
from typing import List, Optional, Dict

class Settings(BaseSettings):
    model_config = SettingsConfigDict(
        env_file=".env",
        env_file_encoding='utf-8',
        extra="ignore"
    )

    APP_NAME: str = "iask-2api"
    APP_VERSION: str = "6.0.0"
    DESCRIPTION: str = "ä¸€ä¸ªå°† iask.ai è½¬æ¢ä¸ºå…¼å®¹ OpenAI æ ¼å¼ API çš„é«˜æ€§èƒ½åŒ¿åä»£ç† (çœŸç†Â·ç»ˆç« )ã€‚"

    API_MASTER_KEY: Optional[str] = None
    
    API_REQUEST_TIMEOUT: int = 180
    NGINX_PORT: int = 8088

    # --- æ¨¡å‹é…ç½® ---
    DEFAULT_MODEL: str = "é€šç”¨é—®ç­” (é€‚åˆæ—¥å¸¸é—®é¢˜)"
    
    # æ¨¡å‹è¯¦ç»†ä¿¡æ¯å­—å…¸
    MODEL_DETAILS: Dict[str, Dict[str, str]] = {
        "question": {
            "display_id": "é€šç”¨é—®ç­” (é€‚åˆæ—¥å¸¸é—®é¢˜)",
            "description": "é€‚ç”¨äºå„ç§æ—¥å¸¸é—®é¢˜å’ŒçŸ¥è¯†æŸ¥è¯¢ï¼Œæä¾›å¿«é€Ÿã€å‡†ç¡®çš„ç­”æ¡ˆã€‚"
        },
        "academic": {
            "display_id": "å­¦æœ¯ç ”ç©¶ (é€‚åˆæ·±åº¦åˆ†æ)",
            "description": "ä¸“æ³¨äºå­¦æœ¯é¢†åŸŸçš„æ·±åº¦åˆ†æï¼Œé€‚åˆè®ºæ–‡å†™ä½œã€æ–‡çŒ®ç»¼è¿°å’Œä¸“ä¸šçŸ¥è¯†æ¢ç´¢ã€‚"
        },
        "thinking": {
            "display_id": "æ·±åº¦æ€è€ƒ (é€‚åˆå¤æ‚æ¨ç†)",
            "description": "æ¨¡æ‹Ÿäººç±»çš„æ·±åº¦æ€è€ƒè¿‡ç¨‹ï¼Œé€æ­¥åˆ†è§£é—®é¢˜ï¼Œé€‚åˆå¤æ‚é€»è¾‘æ¨ç†å’Œå†³ç­–ã€‚"
        },
        "forums": {
            "display_id": "è®ºå›è§‚ç‚¹ (é€‚åˆå¤šæ–¹è§†è§’)",
            "description": "èšåˆå’Œæç‚¼å„å¤§è®ºå›ç¤¾åŒºçš„è®¨è®ºè§‚ç‚¹ï¼Œæä¾›å¤šå…ƒåŒ–çš„å‚è€ƒä¿¡æ¯å’Œå…¬ä¼—æ„è§ã€‚"
        },
        "wiki": {
            "display_id": "ç»´åŸºç™¾ç§‘ (é€‚åˆäº‹å®æŸ¥è¯¢)",
            "description": "åŸºäºç»´åŸºç™¾ç§‘ç­‰çŸ¥è¯†åº“ï¼Œæä¾›é«˜åº¦ç»“æ„åŒ–ã€å‡†ç¡®çš„äº‹å®ä¿¡æ¯å’Œå†å²èƒŒæ™¯ã€‚"
        }
    }

    # ä» MODEL_DETAILS åŠ¨æ€ç”Ÿæˆæ¨¡å‹åˆ—è¡¨
    @property
    def KNOWN_MODELS(self) -> List[str]:
        return list(self.MODEL_DETAILS.keys())

    # åˆ›å»ºä»å‹å¥½IDåˆ°åŸå§‹IDçš„æ˜ å°„ï¼Œç”¨äºå†…éƒ¨è½¬æ¢
    @property
    def DISPLAY_ID_TO_SIMPLE_ID(self) -> Dict[str, str]:
        return {details["display_id"]: simple_id for simple_id, details in self.MODEL_DETAILS.items()}

settings = Settings()


--- æ–‡ä»¶è·¯å¾„: app\providers\__init__.py ---



--- æ–‡ä»¶è·¯å¾„: app\providers\base_provider.py ---

# --- æ–‡ä»¶è·¯å¾„: app/providers/base_provider.py ---

from abc import ABC, abstractmethod
from typing import Union
from fastapi import Request
from fastapi.responses import StreamingResponse, JSONResponse

class BaseProvider(ABC):
    @abstractmethod
    async def chat_completion(
        self,
        request: Request
    ) -> Union[StreamingResponse, JSONResponse]:
        """
        å¤„ç†èŠå¤©è¡¥å…¨è¯·æ±‚ã€‚
        æ¥æ”¶å®Œæ•´çš„ Request å¯¹è±¡ä»¥è®¿é—®æ‰€æœ‰éœ€è¦çš„ä¿¡æ¯ã€‚
        """
        pass

    @abstractmethod
    async def get_models(self) -> JSONResponse:
        """
        è·å–æ¨¡å‹åˆ—è¡¨ã€‚
        """
        pass



--- æ–‡ä»¶è·¯å¾„: app\providers\iask_provider.py ---

# app/providers/iask_provider.py
import logging
import uuid
import asyncio
import json
import re
from typing import Dict, Any, AsyncGenerator
from urllib.parse import urlencode

from playwright.async_api import async_playwright, Page
from fastapi.responses import StreamingResponse
import html2text

from app.core.config import settings
from app.providers.base_provider import BaseProvider
from app.utils.sse_utils import create_sse_data, create_chat_completion_chunk, DONE_CHUNK

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class IaskProvider(BaseProvider):
    """
    iAsk.ai çš„å†…å®¹æä¾›è€…ã€‚
    ä½¿ç”¨ Playwright å®ç°å¹²å‡€çš„ã€å­—ç¬¦çº§å¢é‡æµå¼å“åº”ã€‚
    """
    def __init__(self):
        # --- å¯é…ç½®å‚æ•° ---
        self.max_retries = 3           # æœ€å¤§é‡è¯•æ¬¡æ•°
        self.retry_delay = 5           # é‡è¯•é—´éš”ï¼ˆç§’ï¼‰
        self.total_timeout = 180       # æ€»è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        self.stale_timeout = 15        # å†…å®¹é™æ­¢è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        self.poll_interval = 0.2       # è½®è¯¢é—´éš”ï¼ˆç§’ï¼‰
        
        # --- å†…å®¹æ¸…ç†æ­£åˆ™è¡¨è¾¾å¼ ---
        # åŒ¹é…å¹¶ç§»é™¤å¼€å¤´çš„ "According to www.iAsk.Ai - Ask AI:"
        self.intro_pattern = re.compile(r'^According to www\.iAsk\.Ai - Ask AI:\s*', re.IGNORECASE)
        # åŒ¹é…å¹¶ç§»é™¤æ€è€ƒå‰ç¼€
        self.thinking_pattern = re.compile(r'^(æ€è€ƒ|Thinking)[:ï¼š]\s*', re.IGNORECASE)
        # åŒ¹é…å¹¶ç§»é™¤ç»“å°¾çš„ç‰ˆæƒä¿¡æ¯
        self.copyright_pattern = re.compile(r'\s*Answer Provided by.*?Ask AI\.?\s*$', re.IGNORECASE | re.DOTALL)
        
        # ã€æ ¼å¼åŒ–æ ¸å¿ƒã€‘
        # 1. ç¡®ä¿å¼•ç”¨æ ‡è®°å‰åæœ‰ç©ºæ ¼
        self.citation_space_pattern = re.compile(r'(\S)(\[\d+\])')
        # 2. æ™ºèƒ½æ®µè½åˆ†éš”ï¼šåœ¨å¼•ç”¨æ ‡è®°åè·Ÿä¸€ä¸ªå¤§å†™å­—æ¯å¼€å¤´çš„æ–°å¥å­æ—¶ï¼Œæ’å…¥æ¢è¡Œ
        # ã€ä¿®å¤ç‚¹ã€‘å°†ä¸­æ–‡å¼•å·æ›¿æ¢ä¸ºæ ‡å‡†è‹±æ–‡å¼•å·ï¼Œé¿å…ç¼–ç é—®é¢˜
        self.paragraph_pattern = re.compile(r'(\]\.\s+)(["\']?[\u4e00-\u9fffA-Z])')
        # 3. æ¸…ç†å¤šä½™çš„æ¢è¡Œç¬¦ï¼Œä¿ç•™æœ€å¤šä¸¤ä¸ªè¿ç»­æ¢è¡Œ
        self.newline_pattern = re.compile(r'\n{3,}')

        logger.info("IaskProvider (Playwright-based with Ultimate Clean Streaming) å·²åˆå§‹åŒ–ã€‚")

        # --- ç²¾ç»†é…ç½® html2text ---
        self.h = html2text.HTML2Text()
        self.h.ignore_links = False
        self.h.ignore_images = False
        self.h.ignore_emphasis = False
        self.h.body_width = 0  # ä¸è‡ªåŠ¨æ¢è¡Œ
        self.h.protect_links = True # ä¿æŠ¤é“¾æ¥ä¸è¢«æ„å¤–æ–­å¼€
        self.h.wrap_links = False
        self.h.skip_internal_links = True
        self.h.inline_links = True
        self.h.images_to_alt = False # ä¿ç•™å›¾ç‰‡é“¾æ¥ï¼Œè€Œä¸æ˜¯åªæ›¿æ¢ä¸ºaltæ–‡æœ¬
        self.h.unicode_snob = True # ä½¿ç”¨Unicodeå­—ç¬¦

    def _clean_text_chunk(self, text_chunk: str) -> str:
        """
        ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ¸…ç†æ–‡æœ¬ç‰‡æ®µï¼Œç§»é™¤å¼•å¯¼è¯­ã€ç‰ˆæƒä¿¡æ¯ã€æ€è€ƒå‰ç¼€ï¼Œå¹¶ä¼˜åŒ–æ ¼å¼ã€‚
        """
        # 1. ç§»é™¤å¼€å¤´çš„å¼•å¯¼è¯­
        cleaned_chunk = self.intro_pattern.sub('', text_chunk)
        # 2. ç§»é™¤æ€è€ƒå‰ç¼€
        cleaned_chunk = self.thinking_pattern.sub('', cleaned_chunk)
        # 3. ç§»é™¤ç»“å°¾çš„ç‰ˆæƒä¿¡æ¯
        cleaned_chunk = self.copyright_pattern.sub('', cleaned_chunk)
        
        # 4. æ ¼å¼ä¼˜åŒ–
        # ç¡®ä¿å¼•ç”¨æ ‡è®°å‰åæœ‰ç©ºæ ¼
        cleaned_chunk = self.citation_space_pattern.sub(r'\1 \2', cleaned_chunk)
        # æ™ºèƒ½æ®µè½åˆ†éš”
        cleaned_chunk = self.paragraph_pattern.sub(r'\1\n\n\2', cleaned_chunk)
        # æ¸…ç†å¤šä½™çš„æ¢è¡Œç¬¦
        cleaned_chunk = self.newline_pattern.sub('\n\n', cleaned_chunk)
        
        # 5. å»é™¤é¦–å°¾å¯èƒ½çš„ç©ºç™½
        return cleaned_chunk.strip()

    async def stream_answer(self, prompt: str, model: str) -> AsyncGenerator[str, None]:
        params = {
            'q': prompt,
            'mode': model,
            'options[detail_level]': 'comprehensive',
            'source': 'organic'
        }
        initial_url = f"https://iask.ai/q?{urlencode(params)}"
        
        logger.info(f"æ­¥éª¤ 1: ä½¿ç”¨Playwrightå¼€å§‹æµå¼è®¿é—® URL: {initial_url}")

        async with async_playwright() as p:
            browser = await p.chromium.launch(headless=True)
            page = await browser.new_page()
            
            try:
                await page.goto(initial_url)
                await page.wait_for_selector('#text', timeout=20000)
                logger.info("ç­”æ¡ˆå®¹å™¨ (#text) å·²å‡ºç°ï¼Œå¼€å§‹å­—ç¬¦çº§å¢é‡æµå¼ç›‘å¬...")

                # --- â€œåŒä¿é™©â€ç»“æŸç­–ç•¥ ---
                async def wait_for_related_questions():
                    try:
                        await page.wait_for_selector('#relatedQuestions', timeout=self.total_timeout * 1000)
                        return True
                    except Exception:
                        return False
                
                completion_task = asyncio.create_task(wait_for_related_questions())

                # ä¸»å¾ªç¯ï¼šå­—ç¬¦çº§å¢é‡æµå¼è¯»å–
                last_full_text = ""
                no_change_timer = 0
                total_timer = 0
                
                while not completion_task.done() and no_change_timer < self.stale_timeout and total_timer < self.total_timeout:
                    try:
                        await asyncio.sleep(self.poll_interval)
                        total_timer += self.poll_interval

                        # 1. è·å–å½“å‰å…¨éƒ¨HTMLå¹¶è½¬æ¢ä¸ºå…¨éƒ¨æ–‡æœ¬
                        current_html = await page.inner_html('#text')
                        current_full_text = self.h.handle(current_html).strip()
                        
                        # 2. è®¡ç®—æ–°å¢çš„æ–‡æœ¬ï¼ˆå¢é‡éƒ¨åˆ†ï¼‰
                        if len(current_full_text) > len(last_full_text):
                            # æœ‰æ–°å†…å®¹ï¼Œé‡ç½®é™æ­¢è®¡æ—¶å™¨
                            no_change_timer = 0
                            new_text_chunk = current_full_text[len(last_full_text):]
                            last_full_text = current_full_text
                            
                            # 3. æ¸…ç†æ–‡æœ¬ç‰‡æ®µ
                            cleaned_chunk = self._clean_text_chunk(new_text_chunk)
                            
                            if cleaned_chunk:
                                logger.info(f"æµå¼å‘é€ç‰‡æ®µï¼Œé•¿åº¦: {len(cleaned_chunk)}")
                                yield cleaned_chunk
                        else:
                            # å†…å®¹æ— å˜åŒ–ï¼Œå¢åŠ é™æ­¢è®¡æ—¶å™¨
                            no_change_timer += self.poll_interval
                            logger.info(f"å†…å®¹æ— å˜åŒ–ï¼Œé™æ­¢è®¡æ—¶: {no_change_timer:.1f}s / {self.stale_timeout}s")

                    except Exception as e:
                        logger.error(f"æµå¼è¯»å–å†…å®¹æ—¶å‡ºé”™: {e}")
                        yield f"\n\né”™è¯¯ï¼š{e}"
                        break
                
                # --- å¾ªç¯ç»“æŸï¼Œåˆ¤æ–­åŸå›  ---
                if completion_task.done() and completion_task.result():
                    logger.info("æµå¼ç»“æŸåŸå› ï¼šæ£€æµ‹åˆ° 'People Also Ask' åŒºåŸŸï¼Œç­”æ¡ˆå·²å®Œå…¨ç”Ÿæˆã€‚")
                elif no_change_timer >= self.stale_timeout:
                    logger.info(f"æµå¼ç»“æŸåŸå› ï¼šå†…å®¹å·²é™æ­¢è¶…è¿‡ {self.stale_timeout} ç§’ã€‚")
                elif total_timer >= self.total_timeout:
                    logger.warning(f"æµå¼ç»“æŸåŸå› ï¼šè¾¾åˆ°æ€»è¶…æ—¶æ—¶é—´ {self.total_timeout} ç§’ã€‚")
                else:
                    logger.warning("æµå¼ç»“æŸåŸå› ï¼šæœªçŸ¥å¼‚å¸¸ã€‚")

                # æœ€åå†æ£€æŸ¥ä¸€æ¬¡ï¼Œç¡®ä¿æ²¡æœ‰é—æ¼
                final_html = await page.inner_html('#text')
                final_full_text = self.h.handle(final_html).strip()
                if len(final_full_text) > len(last_full_text):
                    final_chunk = final_full_text[len(last_full_text):]
                    cleaned_final_chunk = self._clean_text_chunk(final_chunk)
                    if cleaned_final_chunk:
                        yield cleaned_final_chunk

            except Exception as e:
                logger.error(f"æµå¼å¤„ç†æµç¨‹ä¸­å‘ç”Ÿé¡¶å±‚é”™è¯¯: {e}", exc_info=True)
                yield f"é”™è¯¯ï¼š{e}"
            finally:
                await browser.close()

    async def chat_completion(self, request_data: Dict[str, Any]) -> StreamingResponse:
        async def stream_generator() -> AsyncGenerator[bytes, None]:
            request_id = f"chatcmpl-{uuid.uuid4()}"
            # ä»è¯·æ±‚ä¸­è·å–æ¨¡å‹åç§°ï¼ˆå¯èƒ½æ˜¯å‹å¥½IDï¼‰
            model_name_from_request = request_data.get("model", settings.DEFAULT_MODEL)
            
            # ã€ä¿®å¤ç‚¹ã€‘å°†å‹å¥½IDè½¬æ¢ä¸ºåŸå§‹IDï¼Œå¹¶è®¾ç½®ä¸€ä¸ªå®‰å…¨çš„å›é€€å€¼
            # å¦‚æœæ‰¾ä¸åˆ°è¯·æ±‚ä¸­çš„æ¨¡å‹ï¼Œåˆ™å›é€€åˆ°é…ç½®æ–‡ä»¶ä¸­è®¾ç½®çš„é»˜è®¤æ¨¡å‹çš„åŸå§‹ID
            default_simple_model = settings.DISPLAY_ID_TO_SIMPLE_ID.get(settings.DEFAULT_MODEL)
            simple_model_name = settings.DISPLAY_ID_TO_SIMPLE_ID.get(model_name_from_request, default_simple_model)
            
            logger.info(f"æ¥æ”¶åˆ°æ¨¡å‹ '{model_name_from_request}'ï¼Œå·²è½¬æ¢ä¸ºå†…éƒ¨ID '{simple_model_name}'")

            question = request_data["messages"][-1]["content"]
            
            try:
                async for markdown_chunk in self.stream_answer(question, simple_model_name):
                    chunk = create_chat_completion_chunk(request_id, model_name_from_request, markdown_chunk)
                    yield create_sse_data(chunk)
                
            except Exception as e:
                logger.error(f"å¤„ç†æµç¨‹ä¸­å‘ç”Ÿé¡¶å±‚é”™è¯¯: {e}", exc_info=True)
                error_message = f"è·å–ç­”æ¡ˆå¤±è´¥: {e}"
                error_chunk = create_chat_completion_chunk(request_id, model_name_from_request, error_message, "stop")
                yield create_sse_data(error_chunk)
            finally:
                yield DONE_CHUNK

        return StreamingResponse(stream_generator(), media_type="text/event-stream")

    async def get_models(self) -> Dict[str, Any]:
        import time
        return {
            "object": "list",
            "data": [
                {
                    "id": details["display_id"],
                    "object": "model",
                    "created": int(time.time()),
                    "owned_by": "iask-2api"
                }
                for details in settings.MODEL_DETAILS.values()
            ]
        }


--- æ–‡ä»¶è·¯å¾„: app\utils\sse_utils.py ---

# --- æ–‡ä»¶è·¯å¾„: app/utils/sse_utils.py ---

import json
import time
from typing import Dict, Any, Optional

DONE_CHUNK = b"data: [DONE]\n\n"

def create_sse_data(data: Dict[str, Any]) -> bytes:
    """å°†å­—å…¸ç¼–ç ä¸º SSE data è¡Œï¼Œç¡®ä¿é ASCII å­—ç¬¦æ­£ç¡®å¤„ç†ã€‚"""
    return f"data: {json.dumps(data, ensure_ascii=False)}\n\n".encode('utf-8')

def create_chat_completion_chunk(
    request_id: str,
    model: str,
    content: str,
    finish_reason: Optional[str] = None
) -> Dict[str, Any]:
    """ä¸ºå¢é‡æµï¼ˆdeltaï¼‰åˆ›å»ºæ ‡å‡†çš„ OpenAI æ ¼å¼æ•°æ®å—ã€‚"""
    return {
        "id": request_id,
        "object": "chat.completion.chunk",
        "created": int(time.time()),
        "model": model,
        "choices": [
            {
                "index": 0,
                "delta": {"content": content} if content is not None else {},
                "finish_reason": finish_reason,
                "logprobs": None,
            }
        ],
    }



